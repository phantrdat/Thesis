\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks}{53}{chapter.195}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:neural-bo}{{3}{53}{Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks}{chapter.195}{}}
\acronymused{gp}
\acronymused{bo}
\acronymused{gp}
\acronymused{bo}
\acronymused{gp}
\acronymused{gp}
\acronymused{dnn}
\acronymused{gp}
\acronymused{dnn}
\acronymused{bnn}
\acronymused{dnn}
\acronymused{bnn}
\acronymused{ntk}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem Setting}{54}{section.196}\protected@file@percent }
\newlabel{section:neural-bo_problem_setting}{{3.1}{54}{Problem Setting}{section.196}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proposed Neural-BO Method}{54}{section.197}\protected@file@percent }
\newlabel{section:neural-bo_proposed_method}{{3.2}{54}{Proposed Neural-BO Method}{section.197}{}}
\acronymused{dnn}
\acronymused{bo}
\acronymused{gp}
\AC@undonewlabel{acro:relu}
\newlabel{acro:relu}{{3.2}{54}{Proposed Neural-BO Method}{section.197}{}}
\acronymused{relu}
\@writefile{toc}{\contentsline {paragraph}{Discussion}{55}{section*.198}\protected@file@percent }
\acronymused{dnn}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Neural Black-box Optimization (Neural-BO)}}{55}{algorithm.199}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:Neural-BO}{{1}{55}{Neural Black-box Optimization (Neural-BO)}{algorithm.199}{}}
\newlabel{line:calculate_var}{{3}{55}{Neural Black-box Optimization (Neural-BO)}{algorithm.199}{}}
\newlabel{line:train_NN}{{6}{55}{Neural Black-box Optimization (Neural-BO)}{algorithm.199}{}}
\newlabel{line:update_Ut}{{7}{55}{Neural Black-box Optimization (Neural-BO)}{algorithm.199}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces TrainNN}}{56}{algorithm.200}\protected@file@percent }
\newlabel{alg:train_NN}{{2}{56}{TrainNN}{algorithm.200}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Theoretical Analysis}{56}{section.201}\protected@file@percent }
\newlabel{section:neural-bo_regret_analysis}{{3.3}{56}{Theoretical Analysis}{section.201}{}}
\acronymused{ntk}
\acronymused{gp}
\acronymused{ts}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\ifthmt@listswap Definition~3.3.1\else \numberline {3.3.1}Definition\fi \thmtformatoptarg {\blx@tocontentsinit {0}\cite {jacot2018neural}}}{56}{definition.203}\protected@file@percent }
\newlabel{def:NTK_matrix}{{3.3.1}{56}{\cite {jacot2018neural}}{definition.203}{}}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.2\else \numberline {3.3.2}Assumption\fi }{56}{assumption.205}\protected@file@percent }
\newlabel{assumption:sufficient_exploration}{{3.3.2}{56}{}{assumption.205}{}}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.3\else \numberline {3.3.3}Assumption\fi }{56}{assumption.207}\protected@file@percent }
\acronymused{rkhs}
\acronymused{ntk}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.4\else \numberline {3.3.4}Assumption\fi }{56}{assumption.209}\protected@file@percent }
\newlabel{assumption:iid_noise}{{3.3.4}{56}{}{assumption.209}{}}
\@writefile{loe}{\contentsline {theorem}{\ifthmt@listswap Theorem~3.3.5\else \numberline {3.3.5}Theorem\fi }{57}{theorem.211}\protected@file@percent }
\newlabel{theorem:neural-bo_main}{{3.3.5}{57}{}{theorem.211}{}}
\@writefile{loe}{\contentsline {remark}{\ifthmt@listswap Remark~3.3.6\else \numberline {3.3.6}Remark\fi }{57}{remark.213}\protected@file@percent }
\acronymused{ntk}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Proof of the Main Theorem}{57}{section.214}\protected@file@percent }
\newlabel{eqn:rkhs_lipschitz}{{3.1}{58}{Proof of the Main Theorem}{equation.215}{}}
\newlabel{proof:theorem_main}{{3.4}{58}{Proof of the Main Theorem}{equation.215}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{60}{section.216}\protected@file@percent }
\newlabel{section:neural-bo_experiments}{{3.5}{60}{Experiments}{section.216}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Experimental Setup}{60}{subsection.217}\protected@file@percent }
\acronymused{gp}
\acronymused{rf}
\acronymused{dnn}
\acronymused{gp}
\acronymused{rf}
\acronymused{dnn}
\acronymused{rf}
\acronymused{dnn}
\acronymused{rf}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Synthetic Benchmarks}{61}{subsection.222}\protected@file@percent }
\newlabel{fig:neural-bo_synthetic_1}{{\caption@xref {fig:neural-bo_synthetic_1}{ on input line 245}}{62}{Synthetic Benchmarks}{figure.caption.223}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The plots show the minimum true value observed after optimizing several synthetic functions over 2000 iterations of our proposed algorithm and 6 baselines. The dimension of each function is shown in the parenthesis.}}{63}{figure.caption.224}\protected@file@percent }
\newlabel{fig:neural-bo_synthetic}{{3.1}{63}{The plots show the minimum true value observed after optimizing several synthetic functions over 2000 iterations of our proposed algorithm and 6 baselines. The dimension of each function is shown in the parenthesis}{figure.caption.224}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The p-values of KS-test "whether the data obtained from running our methods Neural-BO and all baselines are normally distributed".}}{64}{table.caption.225}\protected@file@percent }
\newlabel{tab:ks_test}{{3.1}{64}{The p-values of KS-test "whether the data obtained from running our methods Neural-BO and all baselines are normally distributed"}{table.caption.225}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces One-sided t-tests were employed to assess whether the baseline achieves a lower function value compared to our proposed method, Neural-BO. The null hypothesis $H_0: \mu _\text  {baseline} \le \mu _{\text  {Neural-BO}}$ and the alternative hypothesis: $H_a: \mu _\text  {baseline} > \mu _{\text  {Neural-BO}}$. The p-value corresponding to each test is provided as the first value in each cell. Moreover, to account for multiple hypotheses testing, the Benjamini-Hochberg correction was applied and is reported as the second value in each cell. In the outcome, a "T" indicates that the null hypothesis is rejected, whereas an "F" signifies that it is not rejected.}}{65}{table.caption.226}\protected@file@percent }
\newlabel{tab:t-test}{{3.2}{65}{One-sided t-tests were employed to assess whether the baseline achieves a lower function value compared to our proposed method, Neural-BO. The null hypothesis $H_0: \mu _\text {baseline} \le \mu _{\text {Neural-BO}}$ and the alternative hypothesis: $H_a: \mu _\text {baseline} > \mu _{\text {Neural-BO}}$. The p-value corresponding to each test is provided as the first value in each cell. Moreover, to account for multiple hypotheses testing, the Benjamini-Hochberg correction was applied and is reported as the second value in each cell. In the outcome, a "T" indicates that the null hypothesis is rejected, whereas an "F" signifies that it is not rejected}{table.caption.226}{}}
\newlabel{fig:coco_2d}{{3.2a}{66}{2D}{figure.caption.228}{}}
\newlabel{sub@fig:coco_2d}{{a}{66}{2D}{figure.caption.228}{}}
\newlabel{fig:coco_3d}{{3.2b}{66}{3D}{figure.caption.228}{}}
\newlabel{sub@fig:coco_3d}{{b}{66}{3D}{figure.caption.228}{}}
\newlabel{fig:coco_5d}{{3.2c}{66}{5D}{figure.caption.228}{}}
\newlabel{sub@fig:coco_5d}{{c}{66}{5D}{figure.caption.228}{}}
\newlabel{fig:coco_10d}{{3.2d}{66}{10D}{figure.caption.228}{}}
\newlabel{sub@fig:coco_10d}{{d}{66}{10D}{figure.caption.228}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The results of benchmarking our Neural-BO and the baselines with COCO framework on 24 BBOB noiseless objective functions with four different dimensions \{2,3,5,10\}.}}{66}{figure.caption.228}\protected@file@percent }
\newlabel{fig:coco}{{3.2}{66}{The results of benchmarking our Neural-BO and the baselines with COCO framework on 24 BBOB noiseless objective functions with four different dimensions \{2,3,5,10\}}{figure.caption.228}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Real-world Applications}{67}{subsection.229}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.1}Designing Sensitive Samples for Detection of Model Tampering}{67}{subsubsection.230}\protected@file@percent }
\newlabel{section:neural-bo_sensitive_samples}{{3.5.3.1}{67}{Designing Sensitive Samples for Detection of Model Tampering}{subsubsection.230}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The plot shows the \textbf  {detection rates} corresponding to the number of samples on the MNIST dataset. The larger the number of sensitive samples, the higher the detection rate. As shown in the figure, Neural-BO can generate sensitive samples that achieve nearly 90\% of the detection rate with at least 8 samples.}}{67}{figure.caption.231}\protected@file@percent }
\newlabel{fig:neural-bo_sensitive_sample}{{3.3}{67}{The plot shows the \textbf {detection rates} corresponding to the number of samples on the MNIST dataset. The larger the number of sensitive samples, the higher the detection rate. As shown in the figure, Neural-BO can generate sensitive samples that achieve nearly 90\% of the detection rate with at least 8 samples}{figure.caption.231}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.2}Unknown target document retrieval}{68}{subsubsection.232}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces We search for the most related document for a specified target document in \textbf  {Amazon product reviews} dataset and report the maximum \textbf  {hierachical F1 score} found by all baselines. All methods show similar behaviour and Neural-BO performs comparably and much better than GP-based baselines.}}{68}{figure.caption.233}\protected@file@percent }
\newlabel{fig:text}{{3.4}{68}{We search for the most related document for a specified target document in \textbf {Amazon product reviews} dataset and report the maximum \textbf {hierachical F1 score} found by all baselines. All methods show similar behaviour and Neural-BO performs comparably and much better than GP-based baselines}{figure.caption.233}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.3}Optimizing control parameters for robot pushing}{69}{subsubsection.235}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces  Optimization results for control parameters of 14D robot pushing problem. The X-axis shows iterations, and the y-axis shows the median of the best reward obtained.}}{69}{figure.caption.236}\protected@file@percent }
\newlabel{fig:robot_14D}{{3.5}{69}{Optimization results for control parameters of 14D robot pushing problem. The X-axis shows iterations, and the y-axis shows the median of the best reward obtained}{figure.caption.236}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion}{70}{section.237}\protected@file@percent }
\acronymused{bo}
\acronymused{dnn}
\acronymused{gp}
\@setckpt{Chapters/neural-bo}{
\setcounter{page}{71}
\setcounter{equation}{1}
\setcounter{enumi}{2}
\setcounter{enumii}{6}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{6}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{2}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{174}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{1}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{4}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{parentequation}{0}
\setcounter{thmt@dummyctr}{7}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{AM@survey}{0}
\setcounter{theorem}{0}
\setcounter{sublemma}{0}
\setcounter{section@level}{1}
\setcounter{Item}{45}
\setcounter{Hfootnote}{6}
\setcounter{bookmark@seq@number}{84}
}
