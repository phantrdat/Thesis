\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Black-box Optimization Algorithm using Deep Neural Networks}{58}{chapter.143}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:neural-bo}{{3}{58}{Black-box Optimization Algorithm using Deep Neural Networks}{chapter.143}{}}
\acronymused{gp}
\acronymused{bo}
\acronymused{gp}
\acronymused{gp}
\acronymused{bo}
\acronymused{gp}
\acronymused{dnn}
\acronymused{gp}
\acronymused{dnn}
\acronymused{bnn}
\acronymused{dnn}
\acronymused{bnn}
\acronymused{ntk}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem Setting}{59}{section.144}\protected@file@percent }
\newlabel{section:neural-bo_problem_setting}{{3.1}{59}{Problem Setting}{section.144}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proposed Neural-BO Method}{59}{section.145}\protected@file@percent }
\newlabel{section:neural-bo_proposed_method}{{3.2}{59}{Proposed Neural-BO Method}{section.145}{}}
\acronymused{dnn}
\acronymused{bo}
\acronymused{gp}
\AC@undonewlabel{acro:relu}
\newlabel{acro:relu}{{3.2}{59}{Proposed Neural-BO Method}{section.145}{}}
\acronymused{relu}
\@writefile{toc}{\contentsline {paragraph}{Discussion}{60}{section*.146}\protected@file@percent }
\acronymused{dnn}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces TrainNN}}{60}{algorithm.148}\protected@file@percent }
\newlabel{alg:train_NN}{{2}{60}{TrainNN}{algorithm.148}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Neural Black-box Optimization (Neural-BO)}}{61}{algorithm.147}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:Neural-BO}{{1}{61}{Neural Black-box Optimization (Neural-BO)}{algorithm.147}{}}
\newlabel{line:calculate_var}{{3}{61}{Neural Black-box Optimization (Neural-BO)}{algorithm.147}{}}
\newlabel{line:train_NN}{{6}{61}{Neural Black-box Optimization (Neural-BO)}{algorithm.147}{}}
\newlabel{line:update_Ut}{{7}{61}{Neural Black-box Optimization (Neural-BO)}{algorithm.147}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Theoretical Analysis}{61}{section.149}\protected@file@percent }
\newlabel{section:neural-bo_regret_analysis}{{3.3}{61}{Theoretical Analysis}{section.149}{}}
\acronymused{ntk}
\acronymused{gp}
\acronymused{ts}
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\ifthmt@listswap Definition~3.3.1\else \numberline {3.3.1}Definition\fi \thmtformatoptarg {\blx@tocontentsinit {0}\cite {jacot2018neural}}}{61}{definition.151}\protected@file@percent }
\newlabel{def:NTK_matrix}{{3.3.1}{61}{\cite {jacot2018neural}}{definition.151}{}}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.2\else \numberline {3.3.2}Assumption\fi }{61}{assumption.153}\protected@file@percent }
\newlabel{assumption:sufficient_exploration}{{3.3.2}{61}{}{assumption.153}{}}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.3\else \numberline {3.3.3}Assumption\fi }{61}{assumption.155}\protected@file@percent }
\acronymused{rkhs}
\acronymused{ntk}
\@writefile{loe}{\contentsline {assumption}{\ifthmt@listswap Assumption~3.3.4\else \numberline {3.3.4}Assumption\fi }{62}{assumption.157}\protected@file@percent }
\newlabel{assumption:iid_noise}{{3.3.4}{62}{}{assumption.157}{}}
\@writefile{loe}{\contentsline {theorem}{\ifthmt@listswap Theorem~3.3.5\else \numberline {3.3.5}Theorem\fi }{62}{theorem.159}\protected@file@percent }
\newlabel{theorem:neural-bo_main}{{3.3.5}{62}{}{theorem.159}{}}
\@writefile{loe}{\contentsline {remark}{\ifthmt@listswap Remark~3.3.6\else \numberline {3.3.6}Remark\fi }{62}{remark.161}\protected@file@percent }
\acronymused{ntk}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Proof Sketch of the Main Theorem}{63}{section.162}\protected@file@percent }
\newlabel{eqn:neural-bo_rkhs_lipschitz}{{3.1}{63}{Proof Sketch of the Main Theorem}{equation.163}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiments}{65}{section.164}\protected@file@percent }
\newlabel{section:neural-bo_experiments}{{3.5}{65}{Experiments}{section.164}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Experimental Setup}{65}{subsection.165}\protected@file@percent }
\acronymused{gp}
\acronymused{rf}
\acronymused{dnn}
\acronymused{gp}
\acronymused{rf}
\acronymused{dnn}
\acronymused{rf}
\acronymused{dnn}
\acronymused{rf}
\acronymused{bo}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Synthetic Benchmarks}{66}{subsection.170}\protected@file@percent }
\newlabel{fig:neural-bo_synthetic_1}{{\caption@xref {fig:neural-bo_synthetic_1}{ on input line 250}}{67}{Synthetic Benchmarks}{figure.caption.171}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The plots show the minimum true value observed after optimizing several synthetic functions over 2000 iterations of our proposed algorithm and 6 baselines. The dimension of each function is shown in the parenthesis.}}{68}{figure.caption.172}\protected@file@percent }
\newlabel{fig:neural-bo_synthetic}{{3.2}{68}{The plots show the minimum true value observed after optimizing several synthetic functions over 2000 iterations of our proposed algorithm and 6 baselines. The dimension of each function is shown in the parenthesis}{figure.caption.172}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The p-values of KS-test "whether the data obtained from running our methods Neural-BO and all baselines are normally distributed".}}{69}{table.caption.173}\protected@file@percent }
\newlabel{tab:neural-bo_ks_test}{{3.1}{69}{The p-values of KS-test "whether the data obtained from running our methods Neural-BO and all baselines are normally distributed"}{table.caption.173}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces One-sided t-tests were employed to assess whether the baseline achieves a lower function value compared to our proposed method, Neural-BO. The null hypothesis $H_0: \mu _\text  {baseline} \le \mu _{\text  {Neural-BO}}$ and the alternative hypothesis: $H_a: \mu _\text  {baseline} > \mu _{\text  {Neural-BO}}$. The p-value corresponding to each test is provided as the first value in each cell. Moreover, to account for multiple hypotheses testing, the Benjamini-Hochberg correction was applied and is reported as the second value in each cell. In the outcome, a "T" indicates that the null hypothesis is rejected, whereas an "F" signifies that it is not rejected.}}{70}{table.caption.174}\protected@file@percent }
\newlabel{tab:neural-bo_t-test}{{3.2}{70}{One-sided t-tests were employed to assess whether the baseline achieves a lower function value compared to our proposed method, Neural-BO. The null hypothesis $H_0: \mu _\text {baseline} \le \mu _{\text {Neural-BO}}$ and the alternative hypothesis: $H_a: \mu _\text {baseline} > \mu _{\text {Neural-BO}}$. The p-value corresponding to each test is provided as the first value in each cell. Moreover, to account for multiple hypotheses testing, the Benjamini-Hochberg correction was applied and is reported as the second value in each cell. In the outcome, a "T" indicates that the null hypothesis is rejected, whereas an "F" signifies that it is not rejected}{table.caption.174}{}}
\newlabel{fig:coco_2d}{{3.3a}{71}{2D}{figure.caption.176}{}}
\newlabel{sub@fig:coco_2d}{{a}{71}{2D}{figure.caption.176}{}}
\newlabel{fig:coco_3d}{{3.3b}{71}{3D}{figure.caption.176}{}}
\newlabel{sub@fig:coco_3d}{{b}{71}{3D}{figure.caption.176}{}}
\newlabel{fig:coco_5d}{{3.3c}{71}{5D}{figure.caption.176}{}}
\newlabel{sub@fig:coco_5d}{{c}{71}{5D}{figure.caption.176}{}}
\newlabel{fig:coco_10d}{{3.3d}{71}{10D}{figure.caption.176}{}}
\newlabel{sub@fig:coco_10d}{{d}{71}{10D}{figure.caption.176}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The results of benchmarking our Neural-BO and the baselines with COCO framework on 24 BBOB noiseless objective functions with four different dimensions \{2,3,5,10\}.}}{71}{figure.caption.176}\protected@file@percent }
\newlabel{fig:coco}{{3.3}{71}{The results of benchmarking our Neural-BO and the baselines with COCO framework on 24 BBOB noiseless objective functions with four different dimensions \{2,3,5,10\}}{figure.caption.176}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Real-world Applications}{71}{subsection.177}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.1}Designing Sensitive Samples for Detection of Model Tampering}{71}{subsubsection.178}\protected@file@percent }
\newlabel{section:neural-bo_sensitive_samples}{{3.5.3.1}{71}{Designing Sensitive Samples for Detection of Model Tampering}{subsubsection.178}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The plot shows the detection rates corresponding to the number of samples on the MNIST dataset. The larger the number of sensitive samples, the higher the detection rate. As shown in the figure, Neural-BO can generate sensitive samples that achieve nearly 90\% of the detection rate with at least 8 samples.}}{72}{figure.caption.179}\protected@file@percent }
\newlabel{fig:neural-bo_sensitive_sample}{{3.4}{72}{The plot shows the detection rates corresponding to the number of samples on the MNIST dataset. The larger the number of sensitive samples, the higher the detection rate. As shown in the figure, Neural-BO can generate sensitive samples that achieve nearly 90\% of the detection rate with at least 8 samples}{figure.caption.179}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.2}Unknown target document retrieval}{72}{subsubsection.180}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3.3}Optimizing control parameters for robot pushing}{73}{subsubsection.183}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion}{73}{section.185}\protected@file@percent }
\acronymused{bo}
\acronymused{dnn}
\acronymused{gp}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces We search for the most related document for a specified target document in Amazon product reviews dataset and report the maximum hierachical F1 score found by all baselines. All methods show similar behaviour and Neural-BO performs comparably and much better than GP-based baselines.}}{74}{figure.caption.182}\protected@file@percent }
\newlabel{fig:text}{{3.5}{74}{We search for the most related document for a specified target document in Amazon product reviews dataset and report the maximum hierachical F1 score found by all baselines. All methods show similar behaviour and Neural-BO performs comparably and much better than GP-based baselines}{figure.caption.182}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces  Optimization results for control parameters of 14D robot pushing problem. The X-axis shows iterations, and the y-axis shows the median of the best reward obtained.}}{75}{figure.caption.184}\protected@file@percent }
\newlabel{fig:robot_14D}{{3.6}{75}{Optimization results for control parameters of 14D robot pushing problem. The X-axis shows iterations, and the y-axis shows the median of the best reward obtained}{figure.caption.184}{}}
\@setckpt{Chapters/neural-bo}{
\setcounter{page}{76}
\setcounter{equation}{1}
\setcounter{enumi}{2}
\setcounter{enumii}{6}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{6}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{2}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{195}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{2}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{1}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{2}
\setcounter{ALG@line}{4}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{parentequation}{0}
\setcounter{thmt@dummyctr}{7}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{AM@survey}{0}
\setcounter{theorem}{0}
\setcounter{sublemma}{0}
\setcounter{auxlemma}{0}
\setcounter{section@level}{1}
\setcounter{Item}{44}
\setcounter{Hfootnote}{6}
\setcounter{bookmark@seq@number}{84}
}
