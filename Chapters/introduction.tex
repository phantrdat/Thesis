\chapter{Introduction} % Main chapter title

\label{chap:introduction} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

Science has made a great impact on human prosperity. From healthcare to food production to modern communication, scientific breakthroughs have transformed nearly every facet of life. Many of these breakthroughs arise from experiments conducted on complex, unknown systems, with the aim of discovering which inputs yield the most favorable outputs. Some well-known examples are the synthesis of short polymer fiber materials, alloy design, 3D bio-printing, molecule design, etc., \citep{greenhill2020bayesian, shahriari2015taking}. In many cases, experts rely on informed guesses or prior knowledge to decide which inputs to test. This trial-and-error process typically requires numerous experiments to identify the optimal input, a task that can be both time-consuming and expensive. The high costs, in terms of both financial resources and labor, restrict the extent to which these systems can be optimized, thereby slowing progress in research and industry. Therefore, strategies that help find optimal solutions with fewer trials could significantly speed up innovation.

Bayesian Optimization is one of the most effective methods for optimizing expensive, black-box systems \citep{mockus1978application, streltsov1999non}. It works by using all previous inputs and their corresponding outputs, along with any known information about the system, to build a statistical model of the function. Typically, a probabilistic model such as a \ac{gp} is trained on available observations. This model helps generate an acquisition function that balances exploration (trying new inputs) and exploitation (refining known good inputs). The acquisition function is optimized to suggest the next input to evaluate, and the resulting output is used to update the model. By iterating this process, Bayesian Optimization can identify optimal inputs with far fewer experiments than traditional methods, leading to significant cost savings in both time and resources. 

Mathematically, we can formalize this task as a global optimization problem to optimize $f(\mathbf{x})$ subject to $\mathbf{x} \in \mathcal D \subset \mathbb{R}^d$, where $d$ is the number of dimensions, and $f$ is an expensive black-box system that can only be evaluated point-wise. Without any loss in generality, we assume  $\mathcal D$ to be a $d$-dimensional space. Further, due to different aspects (e.g., measurement noise), we often only have access to noisy evaluations of $f$ in the form $y = f(\mathbf{x}) + \epsilon$, where $\epsilon$ is the noise.

Bayesian Optimization has found widespread use across various disciplines, including materials science, biomedical research, and even other areas of computer science. In materials science, it has contributed to innovations such as the creation of new polymer fibers \citep{li2017rapid}, the analysis of metal oxide grain boundary structures \citep{kikuchi2018bayesian}, and the enhancement of thermal conductivity in nanostructures \citep{ju2017designing}. Within biomedical research, it has been applied to a range of tasks, such as aiding in COVID-19 diagnosis \citep{nour2020novel}, examining the impact of aging on time perception \citep{turgeon2016cognitive}, and designing synthetic genes \citep{gonzalez2015bayesian}. In computer science, Bayesian optimization is frequently utilized to improve robot control \citep{berkenkamp2023bayesian} and fine-tune hyperparameters in machine learning models \citep{snoek2012practical,bergstra2012random}.

One of the most fundamental components in Bayesian Optimization is the \textit{surrogate model}. As an approximation of the true objective function, the surrogate model provides both predictions of the function’s value and estimates of uncertainty for each potential input. This dual output is crucial for designing the acquisition function, which determines the next point to sample in the optimization process. The acquisition function uses the surrogate model's predictions to balance exploration and exploitation. Exploration encourages sampling in regions with high uncertainty, where the model is less confident, in the hope of discovering better solutions. Exploitation, on the other hand, focuses on regions where the surrogate predicts high performance, aiming to refine promising areas. By leveraging the surrogate model’s predictions and uncertainty estimates, the acquisition function can suggest new inputs that strategically advance the search for the optimal solution, often reducing the number of expensive evaluations required.

Due to their flexibility, well-calibrated uncertainty estimates, and favorable analytical properties, \ac{gp} has long been a popular choice for modeling distributions over functions in Bayesian optimization \citep{osborne2009gaussian}. \ac{gp} provide a probabilistic framework that captures not only the predictions of the objective function, but also the uncertainty associated with those predictions, allowing Bayesian optimization to balance exploration and exploitation effectively. Additionally, the ability of \ac{gp} to compute closed-form posterior distributions and acquisition functions, such as \ac{ei} or \ac{ucb}, further enhances their appeal for efficient decision-making in optimization tasks. The combination of Bayesian optimization with \ac{gp} has led to strong theoretical results, particularly in terms of convergence guarantees. For instance, \citet{srinivas2009gaussian} presented rigorous theoretical bounds showing that Bayesian Optimization with GP models can achieve sublinear regret, which means that the performance of the algorithm improves significantly over time as more data is gathered. Moreover, this framework has been successfully extended to more complex settings, including multitask and multi-objective optimization \citep{swersky2013multi}, where \ac{gp} can jointly model several related tasks or objectives, leveraging shared information to improve optimization efficiency across different tasks.

Despite these advantages, \ac{gp} comes with inherent limitations that have motivated further research into alternative models. One major challenge is the computational complexity associated with \ac{gp}, particularly the cubic time complexity for inference, which becomes prohibitive as the dataset grows. This computational burden is especially problematic when handling large-scale problems or high-dimensional input spaces, where \ac{gp} struggle due to the curse of dimensionality. As the number of dimensions increases, the predictive performance of \ac{gp} worsens, and the inference becomes slower, limiting their scalability for real-world applications involving large, high-dimensional datasets.

While \ac{gp} remains the dominant choice for modeling in Bayesian optimization, in response to these challenges,  researchers are actively exploring more alternative models to \ac{gp}, such as \ac{rf}, \ac{bnn}, and \ac{deepgp}. These models aim to retain some of the desirable properties of \ac{gp}, such as uncertainty quantification and flexibility while improving scalability and performance in high-dimensional spaces. For instance, \acfp{rf} and \acp{dnn} have been employed to estimate black-box functions in this context. \acp{rf} tend to perform well at making accurate predictions in the vicinity of the training data. However, they struggle with extrapolation, meaning their performance can significantly deteriorate when making predictions outside the range of observed data points \citep{shahriari2015taking}. Additionally, hybrid approaches that combine \ac{gp} with other models or approximate inference techniques, such as variational methods \citep{tran2016variational} and sparse approximations \citep{snelson2007local}, are being developed to tackle the computational bottlenecks and extend the practical applicability of \ac{gp} and Bayesian Optimization to more complex and large-scale problems.  The first significant application of \ac{dnn} in Bayesian Optimization was introduced by \citet{snoek2015scalable}, who employed a \ac{dnn} to transform high-dimensional inputs into lower-dimensional feature vectors. These feature vectors were then fitted to a Bayesian linear regression surrogate model, allowing for more efficient optimization. Another promising approach was presented in \citet{springenberg2016bayesian}, where the objective function was modeled directly using a \acf{bnn}. This method aimed to capture the complex relationships within the data while providing uncertainty estimates for the predictions. Despite the empirical success of these neural network approaches in Bayesian optimization tasks, a significant gap remains in the theoretical understanding of their convergence properties. Unlike \acp{gp}, which have well-established theoretical frameworks demonstrating their convergence guarantees, the algorithms leveraging neural networks lack similar assurances. This absence of theoretical backing raises questions about the reliability and robustness of these methods in practice, particularly in high-dimensional applications. Moreover, the use of Bayesian linear regression or \acp{bnn} introduces substantial computational challenges. Both approaches require maintaining an ensemble of models to derive the posterior distribution over the parameters, leading to increased complexity and potentially prohibitive computational costs. As the dimensionality of the input space or the size of the dataset grows, the demand for computational resources can become a critical limitation. Consequently, while alternative models like random forests and neural networks present exciting avenues for exploration in Bayesian optimization, further research is \textit{necessary to develop} methods that not only demonstrate empirical efficacy but also provide the theoretical guarantees and computational efficiency needed for practical application.

Real-world optimization problems often come with \textit{unknown constraints}. In this setting, black-box optimization with black-box constraints becomes crucial, as both the objective function and constraints need to be optimized simultaneously while ensuring that evaluations are made within feasible regions. Traditional BO methods, which focus solely on optimizing the objective function, fail to capture the interplay between the unknown constraints and the objective, potentially leading to infeasible or suboptimal solutions. Hence, considering only standard \ac{bo} is insufficient to address such tasks effectively. Many attempts have been made to tackle this challenge by incorporating constraint handling into the BO framework, resulting in methods specifically designed for constrained \ac{bo}\citep{gelbart2014bayesian, ariafar2019admmbo, nguyen2023optimistic}. However, despite these advancements, all of these methods still rely on GPs as the surrogate model, which introduces drawbacks similar to those seen in standard \ac{gp}-based BO, such as poor scalability and increasing computational costs as the number of observations grows. This limitation motivates further \textit{exploration} into more scalable surrogate models, such as \acp{dnn}, to better handle the complexities of black-box optimization with black-box constraints.

Additionally, these constraints could represent physical laws, safety conditions, or other complex requirements that must be satisfied during the optimization process. In many scientific and engineering domains, the objective function and its constraints are governed by well-established physical principles, such as conservation laws, thermodynamics, or fluid dynamics. These principles can often be expressed in the form of \acp{pde} or other mathematical models that describe the underlying system behavior. \textit{Integrating this prior knowledge into the \ac{bo} framework can significantly improve both the efficiency and accuracy of the optimization process}. By leveraging physical knowledge, we not only reduce the need for expensive function evaluations but also ensure that the optimization process remains within physically feasible regions, thereby avoiding solutions that violate fundamental laws. 
Following these motivations, we introduce our main aims and approaches 


\section{Aims and Approaches}
The main objective of this thesis is to improve the performance and scalability of \acl{bo}, especially on structural data.  More specifically, we focus on these targets:
\begin{enumerate}
    \item  As the number of optimization iterations increases, \acp{gp}-based black-box optimization faces computational costs, leading to poor scalability.
    To address this, we propose replacing the traditional \ac{gp} surrogate model with a more scalable alternative - \ac{dnn}. \label{aim:1}
    \item Applying the use of \ac{dnn} surrogate models into black-box optimization with black-box, expensive constraints.  \label{aim:2}
    \item Improving the performance of black-box optimization by integrating useful physical information in the form of \acp{pde}. \label{aim:3}
\end{enumerate}
To realize these aims, we developed our methods around the idea of using \ac{dnn} as the surrogate model. Our works can be summarized as:
\begin{itemize}
    \item To achieve Aim \ref{aim:1}, we replace the conventional \ac{gp} model by a \ac{dnn} surrogate model. We apply a \acl{ts} based strategy for choosing the next evaluation. We named this method as Neural-BO.
    \item To achieve Aim \ref{aim:2}, we apply the \acf{ei} acquisition function to select the next samples within a feasible region, determined by \acf{lcb} conditions for all constraints. The \acs{lcb}-based approach guarantees constraint feasibility, while \acs{ei} efficiently balances exploration and exploitation, especially when the feasible regions are much smaller than the overall search space. We called this method as Neural-CBO.
    \item To achieve Aim \ref{aim:3}, we model the objective function using a \acf{pinn}. By incorporating physical knowledge, expressed through \acp{pde}, into the \ac{pinn} training process, we enhance the sample efficiency of the black-box optimization.  We called this method PINN-BO. 
\end{itemize}
\section{Significant Contributions}
The work presented in this thesis is important as it addresses the scalability limitations found in \acp{gp}-based \acf{bo}. As \ac{bo} is designed for high-cost problems, our approach significantly lowers the computational cost across a wide range of practical tasks. Specifically: 
\begin{itemize}
    \item As \ac{gp} scale poorly with the number of data points, \acp{gp}-based \ac{bo} have to deal with the increasing computational cost when the number of optimization iterations increases. \acp{dnn}-based approaches, such as methods, that rely on \acp{bnn} to manage predictive uncertainty, continue to face computationally efficient challenges. Our Neural-BO algorithm, in contrast,  incorporated recent advances in neural network theory through the use of \ac{ntk} to estimate a confidence interval around the neural network model and employ \acl{ts} technique to determine the next evaluation point. Our theoretical analysis of the algorithm's regret bound demonstrates that it is both convergent and more sample-efficient than existing methods. Furthermore, we show the potential of our Neural-BO algorithm in optimizing complex structured data, such as images and text, while maintaining computational scalability by growing linearly with the number of data points. The experimental results on synthetic benchmarks and real-world optimization tasks highlight that our algorithm outperforms the current state-of-the-art in \ac{bo}.  
    \item In real-world life, \ac{bo} tasks often come along with unknown, expensive constraints. Our Neural-CBO has extended the \ac{dnn}-based idea to this unknown, expensive constraints \ac{bo} problem. By inheriting the good scalability of \acp{dnn},  we modeled both the objective function and constraints using \acp{dnn}, and \ac{ei} is used as the acquisition function. The feasible region is determined using \ac{lcb} conditions, ensuring constraint satisfaction while balancing exploration and exploitation. Our theoretical analysis shows that cumulative regret and constraint violations have upper bounds comparable to Gaussian Process-based methods. Importantly, the convergence of our model only requires network width to scale linearly with the number of observations. Benchmarking experiments on synthetic and real-world tasks demonstrate that Neural-CBO performs competitively with state-of-the-art techniques. 
    \item Many natural phenomena are governed by physical laws, which can be viewed as constraints when modeling these phenomena as underlying black-box functions. Our contribution focuses on the \ac{bo} problem, where the black-box function is subject to physical constraints expressed through \acp{pde}. To address this, we introduce the PINN-BO algorithm, which offers several advantages: enhanced sample efficiency in optimization, scalable computation that grows linearly with the number of function evaluations, and the ability to handle a wide variety of \acp{pde}. We demonstrate that PINN-BO outperforms existing methods that lack physical knowledge across both synthetic and real-world problems. 
\end{itemize}

\section{Structure of this Thesis}
\begin{itemize}
    \item Chapter \ref{chap:background} provides the foundational concepts for our works. We begin by introducing the optimization problem and its variants,  from gradient-based approaches to derivative-free strategies under black-box assumptions on the objective functions. Then we describe black-box optimization and its core components, including surrogate models and acquisition functions. The surrogate models relied on key mathematical tools, such as \ac{gp} and the associated kernels, along with \ac{dnn}, particularly in over-parameterized settings. We then link these models through the lens of \ac{rkhs}. Next, we introduce the trade-off between exploration-exploitation through acquisition functions, with a focus on utility-based acquisition functions (e.g., \ac{ts}, \ac{ei}, and \ac{ucb}). Additionally, we discuss other types of acquisition functions, such as those based on information theory (\ac{es}, \ac{pes}, \ac{mes}). Finally, we discuss Bandit-based Optimization and establish a connection with Black-box Optimization.  
    \item Chapter \ref{chap:neural-bo} describes our \ac{dnn}-based black-box optimization method named Neural-BO. We begin by discussing the motivations behind the approach and explain how to mathematically integrate a \ac{dnn} model with \acs{ts}. Next, we present proof of regret-bound convergence for our proposed method under canonical assumptions.  Finally, we provide experimental results on both real-world and synthetic problems, demonstrating that our method outperforms standard approaches, especially in high-dimensional structural data.  
    \item Chapter \ref{chap:neural-cbo} introduces Neural-CBO method. In this chapter, we utilized the benefit of \ac{dnn}-based surrogate model into black-box optimization under unknown, black-box constraints. We detail how to use \ac{dnn} to model, control the uncertainty and balance the exploration-exploitation of both objective function and constraints. Finally, we provide the theoretical guarantee not only for the cumulative regret of the objective function but also for the constraint violation. Similar to Chapter \ref{chap:neural-bo}, we conduct a wide range of experiments, from synthetic to real-world benchmarks, to demonstrate the effectiveness of our method.     
    \item Chapter \ref{chap:pinn-bo} focuses on the PINN-BO method, which addresses optimization problems where the objective function is governed by physical knowledge, expressed as physics-based constraints. We begin by outlining the physical information in the form of \acp{pde} and then describe how to incorporate this information into the optimization process. The chapter also provides a theoretical analysis of the convergence of this framework, leveraging the properties of this PINN-BO framework, leveraging the properties of \ac{pinn} under \ac{ntk} perspective.
    \item Chapter \ref{chap:conclusion} concludes this thesis with a summary of our research and a discussion of potential future works.
\end{itemize}
