\chapter{Introduction} % Main chapter title

\label{chap:introduction} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

Science has made a great impact on society. From healthcare to food production to modern communication, scientific breakthroughs have transformed nearly every facet of human life. Many of these breakthroughs arise from experiments conducted on complex, unknown systems, with the aim of discovering which inputs yield the most favorable outputs. Some well-known examples are the synthesis of short polymer fiber materials, alloy design, 3D bio-printing, molecule design, etc., \citep{greenhill2020bayesian, shahriari2015taking}. In many cases, experts rely on informed guesses or prior knowledge to decide which inputs to test. This trial-and-error process typically requires numerous experiments to identify the optimal input, a task that can be both time-consuming and expensive. The high costs, in terms of both financial resources and labor, restrict the extent to which these systems can be optimized, thereby slowing progress in research and industry. Therefore, strategies that help find optimal solutions with fewer trials could significantly speed up innovation.

Bayesian Optimization is one of the most effective methods for optimizing expensive, black-box systems \citep{mockus1978application, streltsov1999non}. It works by using all previous inputs and their corresponding outputs, along with any known information about the system, to build a statistical model of the function. Typically, a probabilistic model such as a \acf{gp} is trained on available observations. This model helps generate an acquisition function that balances exploration (trying new inputs) and exploitation (refining known good inputs). The acquisition function is optimized to suggest the next input to evaluate, and the resulting output is used to update the model. By iterating this process, Bayesian Optimization can identify optimal inputs with far fewer experiments than traditional methods, leading to significant cost savings in both time and resources. 

Mathematically, we can formalize this task as a global optimization problem to optimize $f(\mathbf{x})$ subject to $\mathbf{x} \in \mathcal D \subset \mathbb{R}^d$, where $d$ is the number of dimensions, and $f$ is an expensive black-box system that can only be evaluated point-wise. Further, due to various reasons (e.g., imperfect measurements), we often only have access to noisy evaluations of $f$ in the form $y = f(\mathbf{x}) + \epsilon$, where $\epsilon$ is the noise.

Bayesian Optimization has found widespread use across various disciplines, including materials science, biomedical research, and even other areas of computer science. In materials science, it has contributed to innovations such as the creation of new polymer fibers \citep{li2017rapid}, the analysis of metal oxide grain boundary structures \citep{kikuchi2018bayesian}, and the enhancement of thermal conductivity in nanostructures \citep{ju2017designing}. Within biomedical research, it has been applied to a range of tasks, such as aiding in COVID-19 diagnosis \citep{nour2020novel}, examining the impact of aging on time perception \citep{turgeon2016cognitive}, and designing synthetic genes \citep{gonzalez2015bayesian}. In computer science, Bayesian optimization is frequently utilized to improve robot control \citep{berkenkamp2023bayesian} and fine-tune hyperparameters in machine learning models \citep{snoek2012practical,bergstra2012random}.

A key component in Bayesian Optimization is the \textit{surrogate model}. As an approximation of the true objective function, the surrogate model provides both predictions of the functionâ€™s value and estimates of uncertainty for each potential input. This dual output is crucial for designing the acquisition function, which determines the next point to sample in the optimization process. The acquisition function uses the surrogate model's predictions to balance exploration and exploitation. Exploration encourages sampling in regions with high uncertainty, where the model is less confident, in the hope of discovering better solutions. Exploitation, on the other hand, focuses on regions where the surrogate predicts high performance, aiming to refine promising areas. By leveraging the surrogate model's predictions and uncertainty estimates, the acquisition function can suggest new inputs that strategically advance the search for the optimal solution, while minimizing the number of expensive evaluations required.

Due to their flexibility, well-calibrated uncertainty estimates, and favorable analytical properties, \ac{gp} has long been a popular choice for modeling distributions over functions in Bayesian Optimization \citep{osborne2009gaussian}. \ac{gp} provides a probabilistic framework that captures not only the predictions of the objective function, but also the uncertainty associated with those predictions, allowing Bayesian optimization to balance exploration and exploitation effectively. Additionally, the ability of \ac{gp} to compute closed-form posterior distributions and acquisition functions, such as \ac{ei} or \ac{ucb}, further enhances its appeal for efficient decision-making in optimization tasks. The combination of Bayesian Optimization with \ac{gp} has led to strong theoretical results, particularly in terms of convergence guarantees. For instance, \citet{srinivas2009gaussian} presented rigorous theoretical bounds showing that Bayesian Optimization with GP models can achieve sublinear regret, which means that the performance of the algorithm improves efficiently over time as more data is gathered. Moreover, this framework has been successfully extended to more complex settings, including multitask and multi-objective optimization \citep{swersky2013multi}, where \ac{gp} can jointly model several related tasks or objectives, leveraging shared information to improve optimization efficiency across different tasks.

Despite these advantages, \ac{gp} comes with inherent limitations that have motivated further research into alternative models. One major challenge is the computational complexity associated with \ac{gp}, particularly the cubic time complexity for inference, which becomes prohibitive as the dataset (i.e. the set of function evaluations gathered during the optimization process) grows. This computational burden is especially problematic when handling large-scale problems or high-dimensional input spaces, where \ac{gp} struggles due to the curse of dimensionality. 
While \ac{gp} remains the dominant choice for modeling in Bayesian optimization, in response to these challenges,  researchers are actively exploring more alternative models to \ac{gp}, such as \ac{rf}, \ac{bnn}, and \ac{deepgp}. These models aim to retain some of the desirable properties of \ac{gp}, such as uncertainty quantification and flexibility while improving scalability and performance in high-dimensional spaces. For instance, \acfp{rf} and \acfp{dnn} have been employed to estimate black-box functions in this context. \acp{rf} tend to perform well at making accurate predictions in the vicinity of the training data. However, they struggle with extrapolation, meaning their performance can significantly deteriorate when making predictions outside the range of observed data points \citep{shahriari2015taking}. Additionally, hybrid approaches that combine \ac{gp} with other models or approximate inference techniques, such as variational methods \citep{tran2016variational} and sparse approximations \citep{snelson2007local}, are being developed to tackle the computational bottlenecks and extend the practical applicability of \ac{gp} and Bayesian Optimization to more complex and large-scale problems.  The first significant application of \ac{dnn} in Bayesian Optimization was introduced by \citet{snoek2015scalable}, who employed a \ac{dnn} to transform high-dimensional inputs into lower-dimensional feature vectors. These feature vectors were then fitted to a Bayesian linear regression surrogate model, allowing for more efficient optimization. Another promising approach was presented in \citet{springenberg2016bayesian}, where the objective function was modeled directly using a \acf{bnn}. This method aimed to capture the complex relationships within the data while providing uncertainty estimates for the predictions. Despite the empirical success of these neural network approaches in Bayesian optimization tasks, a significant gap remains in the theoretical understanding of their convergence properties. Unlike \acp{gp}, which have well-established theoretical frameworks demonstrating their convergence guarantees, the algorithms leveraging neural networks lack similar assurances. This absence of theoretical backing raises questions about the reliability and robustness of these methods in practice, particularly in high-dimensional applications. Moreover, the use of Bayesian linear regression or \acp{bnn} introduces substantial computational challenges. Both approaches require maintaining an ensemble of models to derive the posterior distribution over the parameters, leading to increased complexity and potentially prohibitive computational costs. As the dimensionality of the input space or the size of the dataset grows, the demand for computational resources can become a critical limitation. Consequently, while alternative models like random forests and neural networks present exciting avenues for exploration in Bayesian optimization, further research is \textit{necessary to develop} methods that not only demonstrate empirical efficacy but also provide the theoretical guarantees and computational efficiency needed for practical application.

Real-world optimization problems often come with \textit{unknown constraints}. In this setting, black-box optimization with black-box constraints becomes crucial, as both the objective function and constraints need to be optimized simultaneously while ensuring that evaluations are made within feasible regions. Traditional \ac{bo} methods, which focus solely on optimizing the objective function, fail to capture the interplay between the unknown constraints and the objective, potentially leading to infeasible or suboptimal solutions. Hence, considering only standard \ac{bo} is insufficient to address such tasks effectively. Many attempts have been made to tackle this challenge by incorporating constraint handling into the \ac{bo} framework, resulting in methods specifically designed for constrained \ac{bo} \citep{gelbart2014bayesian, ariafar2019admmbo, nguyen2023optimistic}. However, despite these advancements, all of these methods still rely on \acp{gp} as the surrogate model, which introduces drawbacks similar to those seen in standard \ac{gp}-based \ac{bo}, such as poor scalability and increasing computational costs as the number of observations grows. This limitation motivates further \textit{exploration} into more scalable surrogate models, such as \acp{dnn}, to better handle the complexities of black-box optimization with black-box constraints.

In many scientific and engineering domains, the objective function and its constraints are governed by well-established physical principles, such as conservation laws, thermodynamics, or fluid dynamics. These principles can often be expressed in the form of \acp{pde} or other mathematical models that describe the underlying system behavior. \textit{Integrating this prior knowledge into the \ac{bo} framework can significantly improve both the efficiency and accuracy of the optimization process}. By leveraging physical knowledge, we not only reduce the need for expensive function evaluations but also ensure that the optimization process remains within physically feasible regions, thereby avoiding solutions that violate fundamental laws. Following these motivations, we introduce our main aims and approaches.


\section{Aims and Approaches}
The main objective of this thesis is to improve the performance and scalability of \acl{bo}, especially on structural data.  More specifically, we focus on these aims:
\begin{enumerate}[label= Aim \arabic*, align=left]
    \item As the number of optimization iterations increases, \acp{gp}-based black-box optimization faces computational costs, leading to poor scalability. To address this, we aim to develop a scalable BO method replacing the traditional \ac{gp} surrogate model with a more scalable alternative - \ac{dnn}. \label{aim:1}
    \item We aim to use \ac{dnn} surrogate models into black-box optimization with black-box, expensive constraints.  \label{aim:2}
    \item We aim to improve the performance of black-box optimization by integrating useful physical information in the form of \acfp{pde}. \label{aim:3}
\end{enumerate}
To realize these aims, we have developed \ac{dnn}-based methods that are both computationally efficient, scalable and come with rigorous theoretical guarantees on their sample efficiency. We briefly summarize them below:
\begin{itemize}
    \item To achieve \ref{aim:1}, we replace the conventional \ac{gp} model by a \ac{dnn} surrogate model. We propose a novel a \acl{ts} based strategy for choosing the next evaluation. We name this method as Neural-BO.
    \item To achieve \ref{aim:2}, we construct an \acf{ei} acquisition function to select the next samples within a feasible region, determined by \acf{lcb} conditions for all constraints. The \acs{lcb}-based approach guarantees constraint feasibility, while \acs{ei} efficiently balances exploration and exploitation, especially when the region is significantly smaller than the overall search space. We call this method as Neural-CBO.
    \item To achieve \ref{aim:3}, we model the objective function using a \acf{pinn}. By incorporating physical knowledge, expressed through \acp{pde}, into the \ac{pinn} training process, we enhance the sample efficiency of the black-box optimization.  We call this method PINN-BO. 
\end{itemize}
\section{Significant Contributions}
The work presented in this thesis is important as it addresses the scalability limitations found in \acp{gp}-based \acf{bo}. As \ac{bo} is often used in expensive problem settings, our approach significantly lowers both the computational and experimental cost across a wide range of practical tasks. Specifically: 
\begin{itemize}
    \item As \acp{gp} scale poorly with the number of data points, \ac{gp}-based \ac{bo} have to deal with the increasing computational cost when the number of optimization iterations increases. \acp{dnn}-based approaches, such as methods, that rely on \acp{bnn} to manage predictive uncertainty, continue to face computational challenges. Our Neural-BO algorithm, in contrast,  incorporates recent advances in neural network theory through the use of \ac{ntk} to estimate a confidence interval around the neural network model and employs a \acl{ts} technique to determine the next evaluation point. Our theoretical analysis of the NeuralBO's regret bound demonstrates that it is both convergent and more sample-efficient than existing \ac{gp}-based methods. Furthermore, we show the potential of our Neural-BO algorithm in optimizing complex structured data, such as images and text, while maintaining a computational complexity that only grows linearly with the number of data points. The experimental results on synthetic benchmarks and real-world optimization tasks highlight that our algorithm outperforms the current state-of-the-art in \ac{bo}.  
    \item In real-world situations, \ac{bo} tasks often come along with unknown, expensive constraints. Our Neural-CBO has extended the \ac{dnn}-based idea to this unknown, expensive constraints \ac{bo} problem. By inheriting the good scalability of \acp{dnn},  we modeled both the objective function and constraints using \acp{dnn}, and used \ac{ei} as the acquisition function. The feasible region is determined using \ac{lcb} conditions, ensuring constraint satisfaction while balancing exploration and exploitation. Our theoretical analysis shows that cumulative regret and constraint violations have upper bounds comparable to Gaussian Process-based methods. Benchmarking experiments on synthetic and real-world tasks demonstrate that Neural-CBO performs competitively with state-of-the-art techniques. 
    \item We focus on a \ac{bo} problem, where the black-box function is governed by physical laws through \acp{pde}. To address this, we introduce the PINN-BO algorithm, which offers several advantages: enhanced sample efficiency in optimization, scalable computation that grows linearly with the number of function evaluations, and the ability to handle a wide variety of \acp{pde}. We theoretically analyse our algorithm and prove that its regret bound is tighter than the case when PDE information is not utilized. We empirically demonstarte that PINN-BO outperforms existing methods that do not incorporate physical knowledge across both synthetic and real-world problems. 
\end{itemize}

\section{Structure of this Thesis}
\begin{itemize}
    \item Chapter \ref{chap:background} provides a background and discussion of the related works relevant to this thesis. We begin by introducing the optimization problem and its variants,  from gradient-based approaches to derivative-free strategies under black-box assumptions on the objective functions. Then we describe black-box optimization and its core components, including surrogate models and acquisition functions. We discuss various surrogate models, such as \acp{gp} with their associated kernels, and \acp{dnn}, particularly in over-parameterized settings, highlighting their reliance on key mathematical tools. We then link these models through the lens of \ac{rkhs}. Next, we introduce the trade-off between exploration-exploitation through acquisition functions, with a focus on utility-based acquisition functions (e.g., \ac{ts}, \ac{ei}, and \ac{ucb}). Additionally, we discuss other types of acquisition functions, such as those based on information theory (\ac{es}, \ac{pes}, \ac{mes}). We also discuss Bandit-based Optimization and establish a connection with Black-box Optimization. Finally, we conclude with the open problems that guide the work carried out in this thesis.  
    \item Chapter \ref{chap:neural-bo} presents our \ac{dnn}-based black-box optimization method named Neural-BO. We begin by discussing the motivations behind the approach and explain how to mathematically integrate a \ac{dnn} model with \acl{ts}. Next, we present the theoretical analysis (regret bound) for our proposed method under regular assumptions.  Finally, we provide experimental results on both real-world and synthetic optimization problems, demonstrating that our method outperforms current approaches, especially in high-dimensional structural data.  
    \item Chapter \ref{chap:neural-cbo} presents the Neural-CBO method, which utilizes the benefit of \ac{dnn}-based surrogate model into black-box optimization under unknown, black-box constraints. We detail how to use \ac{dnn} to model, control the uncertainty and balance the exploration-exploitation of both objective function and constraints. Finally, we provide a theoretical guarantee for not only  the cumulative regret of the objective function but also for the constraint violation. Similar to Chapter \ref{chap:neural-bo}, we conduct a wide range of experiments, from synthetic to real-world benchmarks, to demonstrate the effectiveness of our method.     
    \item Chapter \ref{chap:pinn-bo} presents the PINN-BO method, which addresses optimization problems where the objective function is governed by physical knowledge, expressed as \acp{pde}. We begin by presenting our optimization problem setting involving the PDEs. We next describe various components of our efficient optimization algorithm PINN-BO. We then provide a theoretical analysis of the convergence of PINN-BO leveraging the properties of \ac{pinn} under \ac{ntk} perspective.
    \item Chapter \ref{chap:conclusion} concludes this thesis with a summary of our contributions and a discussion of potential future works.
\end{itemize}
